{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63da6270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from tabulate import tabulate\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d7efb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function to generate the 1st Itemset with its support value.\n",
    "def gen_C1(transactions):\n",
    "    c1 = []\n",
    "    Dict = {}\n",
    "    for trans in transactions:\n",
    "        for item in trans:\n",
    "            if item not in Dict:\n",
    "                Dict[item] = 1\n",
    "            else:\n",
    "                 Dict[item] = Dict[item] + 1\n",
    "    for i in Dict:\n",
    "        t = []\n",
    "        t.append(i)\n",
    "        c1.append(t)\n",
    "        c1.append(Dict[i])\n",
    "        t = []\n",
    "    return c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35a1e122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to generate frequent itemset i.e L(k) sets for K iteration by passing the previous candidate set C(k-1) as input to the function.\n",
    "def get_frequent_itemSet(transactions,prev_c,frequent_set):\n",
    "    frequent_Itemset = []\n",
    "    for i in range(len(prev_c)):\n",
    "        if i%2 != 0:\n",
    "            support_value = (prev_c[i] * 1.0 / nums_transactions) * 100\n",
    "            #support_value = (prev_c[i] / nums_transactions)\n",
    "            if support_value < min_support:\n",
    "                discarded_itemset.append(prev_c[i-1])\n",
    "            else:\n",
    "                frequent_Itemset.append(prev_c[i-1])\n",
    "                frequent_Itemset.append(prev_c[i])\n",
    "\n",
    "    for items in frequent_Itemset:\n",
    "        frequent_set.append(items)\n",
    "\n",
    "    if len(frequent_Itemset) == 2 or len(frequent_Itemset) == 0:\n",
    "        return_set = frequent_set\n",
    "    #if len(frequent_Itemset)<=2:\n",
    "        #print(\"This will be returned\")\n",
    "        return return_set\n",
    "\n",
    "    else:\n",
    "        get_next_c(transactions, discarded_itemset, frequent_Itemset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d43a3700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to generate Candidate sets by taking previous frequent sets as the input.\n",
    "def get_next_c(transactions, prev_discarded_itemset, frequent_Itemset):\n",
    "    itemset = []\n",
    "    combination_set = []\n",
    "    combination_set_sorted= []\n",
    "    combination_set_unique = []\n",
    "    current_c = []\n",
    "    for i in range(len(frequent_Itemset)):\n",
    "        if i%2 == 0:\n",
    "            itemset.append(frequent_Itemset[i])\n",
    "    for item in itemset:\n",
    "        l = itemset.index(item)\n",
    "        temp = []\n",
    "        for i in range(l + 1, len(itemset)):\n",
    "            \n",
    "            for j in item:\n",
    "                if j not in temp:\n",
    "                    temp.append(j)\n",
    "            for k in itemset[i]:\n",
    "                if k not in temp:\n",
    "                    temp.append(k)\n",
    "                    \n",
    "            combination_set.append(temp)\n",
    "            #reset temp\n",
    "            temp = []\n",
    "            \n",
    "    \n",
    "    for i_set in combination_set:\n",
    "        combination_set_sorted.append(sorted(i_set))\n",
    "        \n",
    "    #Filter out unique item set    \n",
    "    for s_set in combination_set_sorted:\n",
    "        if s_set not in combination_set_unique:\n",
    "            combination_set_unique.append(s_set)\n",
    "    combination_set = combination_set_unique\n",
    "    \n",
    "    for item in combination_set:\n",
    "        counter = 0\n",
    "        for trans in transactions:\n",
    "            if set(item).issubset(set(trans)):\n",
    "                counter += 1\n",
    "        if counter != 0:\n",
    "            current_c.append(item)\n",
    "            current_c.append(counter)\n",
    "    \n",
    "    get_frequent_itemSet(transactions,current_c,frequent_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55de1524",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function to generates Association Rules\n",
    "def generate_rules(freq_set):\n",
    "    rules = []\n",
    "    for item in freq_set:\n",
    "        if isinstance(item, list):\n",
    "            if len(item) != 0:\n",
    "                dec_length = len(item) - 1\n",
    "                while dec_length > 0:\n",
    "                    t = []\n",
    "                    k = []\n",
    "                    comb = list(itertools.combinations(item, dec_length))\n",
    "                    for j in comb:\n",
    "                        k = set(item) - set(j)\n",
    "                        t.append(list(k))\n",
    "                        t.append(list(j))\n",
    "                        rules.append(t)\n",
    "                        t = []\n",
    "                    dec_length = dec_length - 1\n",
    "    return rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a9b830ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to displays the final output of the apriori algorithm by passing Association Rules as the input\n",
    "def display_associations(rules, transactions):\n",
    "    association_rules = []\n",
    "    for rule in rules:\n",
    "        counter_x = 0\n",
    "        counter_xy = 0\n",
    "        \n",
    "        for trans in transactions:\n",
    "            if set(rule[0]).issubset(set(trans)):\n",
    "                counter_x += 1\n",
    "            if set(rule[0] + rule[1]).issubset(set(trans)):\n",
    "                counter_xy += 1\n",
    "         \n",
    "        \n",
    "        #calculate support: support(x)=count(x) in transaction/total number of transactions\n",
    "        support_x = 0\n",
    "        support_x = (counter_x * 1.0 / nums_transactions) * 100\n",
    "        \n",
    "        support_xy = 0\n",
    "        support_xy = (counter_xy * 1.0 / nums_transactions) * 100\n",
    "        \n",
    "        \n",
    "        #calculate confidence: confidence(x->y) = support(x->y)/support(x)\n",
    "        confidence_xy = (support_xy / support_x) * 100\n",
    "        \n",
    "        \n",
    "        if confidence_xy >= min_confidence:\n",
    "            #supportOfXAppendString = \"Support Of X: \" + str(round(supportOfXinPercentage, 2))\n",
    "            support_xandy = \"Support of X -> Y: \" + str(round(support_xy))\n",
    "            confidence_xandy = \"Confidence: \" + str(round(confidence_xy))\n",
    "\n",
    "            #association_rules.append(supportOfXAppendString)\n",
    "            association_rules.append(rule)\n",
    "            association_rules.append(support_xandy)\n",
    "            association_rules.append(confidence_xandy)\n",
    "\n",
    "    return association_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fe408890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Dataset 1 ----\n",
      "Enter minimum Support percentile: 10\n",
      "Enter minimum Confidence percentile: 10\n",
      "\n",
      "\n",
      "Candidate Set (C1): \n",
      "[['wine'], ['clocks'], ['donuts'], ['Wall prints'], ['cooking oils'], ['spices'], ['tea'], ['milk'], ['printers'], ['MP3 players'], ['paper shredders'], ['laptops'], ['Vases'], ['Novelty Makeup'], ['coffee'], ['cell phones'], ['Removals'], ['flatscreen TVs'], ['television sets'], ['DVD players'], ['Perfumes'], ['sugar'], ['Candles'], ['Table lamps'], ['Rugs'], ['Dyes']]\n",
      "\n",
      " Association Rules: \n",
      "\n",
      "\n",
      "['wine']------>['clocks']  Support of X -> Y: 10  Confidence: 40  \n",
      "\n",
      "['clocks']------>['wine']  Support of X -> Y: 10  Confidence: 50  \n",
      "\n",
      "['wine']------>['donuts']  Support of X -> Y: 10  Confidence: 40  \n",
      "\n",
      "['donuts']------>['wine']  Support of X -> Y: 10  Confidence: 67  \n",
      "\n",
      "['wine']------>['television sets']  Support of X -> Y: 10  Confidence: 40  \n",
      "\n",
      "['television sets']------>['wine']  Support of X -> Y: 10  Confidence: 50  \n",
      "\n",
      "['donuts']------>['clocks']  Support of X -> Y: 10  Confidence: 67  \n",
      "\n",
      "['clocks']------>['donuts']  Support of X -> Y: 10  Confidence: 50  \n",
      "\n",
      "['clocks']------>['Wall prints']  Support of X -> Y: 10  Confidence: 50  \n",
      "\n",
      "['Wall prints']------>['clocks']  Support of X -> Y: 10  Confidence: 33  \n",
      "\n",
      "['printers']------>['Wall prints']  Support of X -> Y: 10  Confidence: 67  \n",
      "\n",
      "['Wall prints']------>['printers']  Support of X -> Y: 10  Confidence: 33  \n",
      "\n",
      "['Wall prints']------>['Vases']  Support of X -> Y: 10  Confidence: 33  \n",
      "\n",
      "['Vases']------>['Wall prints']  Support of X -> Y: 10  Confidence: 29  \n",
      "\n",
      "['tea']------>['cooking oils']  Support of X -> Y: 10  Confidence: 50  \n",
      "\n",
      "['cooking oils']------>['tea']  Support of X -> Y: 10  Confidence: 67  \n",
      "\n",
      "['printers']------>['Vases']  Support of X -> Y: 10  Confidence: 67  \n",
      "\n",
      "['Vases']------>['printers']  Support of X -> Y: 10  Confidence: 29  \n",
      "\n",
      "['paper shredders']------>['Vases']  Support of X -> Y: 10  Confidence: 67  \n",
      "\n",
      "['Vases']------>['paper shredders']  Support of X -> Y: 10  Confidence: 29  \n",
      "\n",
      "['laptops']------>['Vases']  Support of X -> Y: 10  Confidence: 100  \n",
      "\n",
      "['Vases']------>['laptops']  Support of X -> Y: 10  Confidence: 29  \n",
      "\n",
      "['coffee']------>['Novelty Makeup']  Support of X -> Y: 10  Confidence: 100  \n",
      "\n",
      "['Novelty Makeup']------>['coffee']  Support of X -> Y: 10  Confidence: 67  \n",
      "\n",
      "['television sets']------>['DVD players']  Support of X -> Y: 10  Confidence: 50  \n",
      "\n",
      "['DVD players']------>['television sets']  Support of X -> Y: 10  Confidence: 50  \n",
      "\n",
      "['television sets']------>['Perfumes']  Support of X -> Y: 10  Confidence: 50  \n",
      "\n",
      "['Perfumes']------>['television sets']  Support of X -> Y: 10  Confidence: 100  \n",
      "\n",
      "['wine']------>['clocks', 'donuts']  Support of X -> Y: 10  Confidence: 40  \n",
      "\n",
      "['donuts']------>['clocks', 'wine']  Support of X -> Y: 10  Confidence: 67  \n",
      "\n",
      "['clocks']------>['donuts', 'wine']  Support of X -> Y: 10  Confidence: 50  \n",
      "\n",
      "['wine', 'donuts']------>['clocks']  Support of X -> Y: 10  Confidence: 100  \n",
      "\n",
      "['clocks', 'wine']------>['donuts']  Support of X -> Y: 10  Confidence: 100  \n",
      "\n",
      "['clocks', 'donuts']------>['wine']  Support of X -> Y: 10  Confidence: 100  \n",
      "\n",
      " Execution_Time:  0.02225780487060547\n"
     ]
    }
   ],
   "source": [
    "#Initialization & data loading\n",
    "\n",
    "\n",
    "filename = \"/Users/komaluntwal/Desktop/apriori_implementation/dataset1.txt\"\n",
    "print('--- Dataset 1 ----')\n",
    "\n",
    "# User Defined minimum support & minimum confidence value\n",
    "min_Support = input('Enter minimum Support percentile: ')\n",
    "min_support = int(min_Support)\n",
    "\n",
    "min_Confidence = input('Enter minimum Confidence percentile: ')\n",
    "min_confidence = int(min_Confidence)\n",
    "print(\"\\n\") \n",
    "\n",
    "## ------------------------------------- # execution time start -----------\n",
    "Start_Time = time.time()\n",
    "##-------------------------------------------------------------------------\n",
    "\n",
    "# Loading Transactions\n",
    "transactions=[]\n",
    "with open(filename,'r') as fp:\n",
    "    lines = fp.readlines()\n",
    "for trans in lines:\n",
    "    trans = trans.rstrip()\n",
    "    transactions.append(trans.split(\",\"))\n",
    "\n",
    "nums_transactions = len(transactions)\n",
    "\n",
    "#temporary storage\n",
    "discarded_itemset = []\n",
    "frequent_set = []\n",
    "\n",
    "#generate c1: first candidate itemset\n",
    "C1 = gen_C1(transactions)\n",
    "print('Candidate Set (C1): ')\n",
    "candidate_set_c1 = []\n",
    "for i in range(len(C1)):\n",
    "    if i%2 == 0:\n",
    "        candidate_set_c1.append(C1[i])\n",
    "print(candidate_set_c1)        \n",
    "        \n",
    "\n",
    "#Generate subsequent L & C sets orf frequent itemset based on previously obtained frequent set\n",
    "frequent_ItemSet = get_frequent_itemSet(transactions,C1,frequent_set)\n",
    "#print('frequent_ItemSet: ', frequent_ItemSet)\n",
    "\n",
    "#Association Rules:\n",
    "Rules = generate_rules(frequent_set)\n",
    "Association_Rules = display_associations(Rules, transactions)\n",
    "\n",
    "\n",
    "#for rule in Association_Rules:\n",
    "#    print(rule)\n",
    "\n",
    "print('\\n Association Rules: ' )\n",
    "inc_ = 3\n",
    "for rule in Association_Rules:\n",
    "    if inc_ == 3 :\n",
    "        print('\\n')\n",
    "        print(str(rule[0]) + \"------>\" + str(rule[1]),end='  ')\n",
    "        inc_ = 0\n",
    "    else:\n",
    "        print(rule, end='  ')\n",
    "    inc_ += 1\n",
    "    \n",
    "## ------------------------------------- # execution time start -----------\n",
    "Execution_Time = time.time() - Start_Time\n",
    "##-------------------------------------------------------------------------\n",
    "\n",
    "print('\\n\\n Execution_Time: ', Execution_Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3b09e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
